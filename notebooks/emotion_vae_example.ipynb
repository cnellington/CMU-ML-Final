{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import multiprocessing as mp\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout, Conv2DTranspose, Reshape\n",
    "from tensorflow.keras.backend import random_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy, mean_squared_error\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.regularizers import L1\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 28709\n",
      "Validation: 3589\n",
      "Test: 3589\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.load('../FER_plus.npz', allow_pickle=True)\n",
    "\n",
    "# Training data\n",
    "X_train = np.expand_dims(data['xtrain'], axis=-1).astype(np.float) * 1./255\n",
    "Y_train = data['ytrain']\n",
    "\n",
    "print('Train: {}'.format(X_train.shape[0]))\n",
    "\n",
    "# Validation data\n",
    "X_val = np.expand_dims(data['xvalid'], axis=-1).astype(np.float) * 1./255\n",
    "Y_val = data['yvalid']\n",
    "\n",
    "print('Validation: {}'.format(X_val.shape[0]))\n",
    "\n",
    "# Test data\n",
    "X_test = np.expand_dims(data['xtest'], axis=-1).astype(np.float) * 1./255\n",
    "Y_test = data['ytest']\n",
    "\n",
    "print('Test: {}'.format(X_test.shape[0]))\n",
    "\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EmotionVAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 48, 48, 16)   160         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 24, 24, 16)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 24, 32)   4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 12, 12, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2304)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 100)          230500      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 100)          230500      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Sampling (Sampling)             (None, 100)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reconDecoderVAE (Functional)    (None, 48, 48, 1)    292865      Sampling[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "emotionDecoderVAE (Functional)  (None, 10)           8874        Sampling[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None, 100)]        0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 100)]        0           z_log_var[0][0]                  \n",
      "                                                                 tf_op_layer_Square[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp (TensorFlowOpLa [(None, 100)]        0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 100)]        0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 tf_op_layer_Exp[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 100)]        0           tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [()]                 0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [()]                 0           tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [()]                 0           tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf_op_layer_Mul_1[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 786,035\n",
      "Trainable params: 786,035\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emotion_vae = EmotionVAE(100)\n",
    "emotion_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_vae.model.load_weights('./emotion_vae_ckpt')\n",
    "#history = emotion_vae.fit(X_train, [X_train, Y_train], val_data=(X_val, [X_val, Y_val]), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
